# üöÄ TO√ÄN T·∫¨P OPENAI API ‚Äî X√ÇY D·ª∞NG H·ªÜ TH·ªêNG AI TH·ª∞C T·∫æ

*(D√†nh cho k·ªπ s∆∞ AI/LLM Developer ‚Äì chu·∫©n ph·ªèng v·∫•n k·ªπ thu·∫≠t)*

---

## üß† PH·∫¶N 1: KI·∫æN TR√öC & C∆† CH·∫æ HO·∫†T ƒê·ªòNG C·ª¶A OPENAI API

---

### üß© 1.1 Ki·∫øn tr√∫c c∆° b·∫£n

OpenAI API l√† **n·ªÅn t·∫£ng ƒë√°m m√¢y** cho ph√©p g·ªçi c√°c m√¥ h√¨nh ng√¥n ng·ªØ (GPT, embedding, moderation‚Ä¶) qua REST API ho·∫∑c th∆∞ vi·ªán Python.

* Th√†nh ph·∫ßn ch√≠nh:

  * **Model** ‚Üí T√™n m√¥ h√¨nh (v√≠ d·ª• `"gpt-4o-mini"`, `"text-embedding-3-large"`)
  * **Messages** ‚Üí Danh s√°ch h·ªôi tho·∫°i (`system`, `user`, `assistant`)
  * **Response** ‚Üí ƒê·∫ßu ra m√¥ h√¨nh (text ho·∫∑c JSON)

### üß© 1.2 C·∫•u tr√∫c m·ªôt API call c∆° b·∫£n

```python
from openai import OpenAI
client = OpenAI(api_key="YOUR_API_KEY")

response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "user", "content": "Who developed ChatGPT?"}
    ]
)

print(response.choices[0].message.content)
```

**Output:**

```
ChatGPT was developed by OpenAI, an artificial intelligence research lab.
```

üß† *Ph·ªèng v·∫•n:*

> ‚ÄúC·∫•u tr√∫c m·ªôt request c·ªßa OpenAI API g·ªìm g√¨?‚Äù
> ‚úÖ Tr·∫£ l·ªùi: ‚ÄúModel + Messages + (tu·ª≥ ch·ªçn) response_format, tools, temperature, max_tokens...‚Äù

---

### üß© 1.3 ƒê·ªãnh d·∫°ng JSON c√≥ c·∫•u tr√∫c

D√πng `response_format` ƒë·ªÉ √©p m√¥ h√¨nh tr·∫£ JSON chu·∫©n ‚Äî r·∫•t quan tr·ªçng khi t√≠ch h·ª£p v·ªõi backend.

```python
response = client.chat.completions.create(
  model="gpt-4o-mini",
  messages=[
    {"role": "user", "content": "List 5 trees with their scientific names in JSON."}
  ],
  response_format={"type": "json_object"}
)

print(response.choices[0].message.content)
```

**Output:**

```json
{
  "trees": [
    {"commonName": "Oak", "scientificName": "Quercus"},
    {"commonName": "Maple", "scientificName": "Acer"},
    {"commonName": "Pine", "scientificName": "Pinus"},
    {"commonName": "Birch", "scientificName": "Betula"},
    {"commonName": "Willow", "scientificName": "Salix"}
  ]
}
```

---

## ‚öôÔ∏è PH·∫¶N 2: L·∫¨P TR√åNH H·ªÜ TH·ªêNG AI ‚Äî L√ÄM CH·ª¶ FUNCTION CALLING

---

### üß† 2.1 Kh√°i ni·ªám Function Calling

**Function Calling** l√† c∆° ch·∫ø cho ph√©p m√¥ h√¨nh **t·ª± ƒë·ªông g·ªçi c√°c h√†m Python ho·∫∑c API ngo√†i** ƒë·ªÉ l·∫•y th√¥ng tin ch√≠nh x√°c h∆°n, gi√∫p m√¥ h√¨nh t·ª´ ‚Äúchatbot tƒ©nh‚Äù tr·ªü th√†nh ‚Äúagent ƒë·ªông‚Äù.

---

### üß© 2.2 C·∫•u tr√∫c m·ªôt function

```python
function_definition = [{
  "type": "function",
  "function": {
    "name": "extract_job_info",
    "description": "Get job information from text",
    "parameters": {
      "type": "object",
      "properties": {
        "job": {"type": "string", "description": "Job title"},
        "location": {"type": "string", "description": "Location"}
      },
      "required": ["job", "location"]
    }
  }
}]
```

---

### üß© 2.3 G·ªçi function trong Chat Completion

```python
response = client.chat.completions.create(
  model="gpt-4o-mini",
  messages=[{"role": "user", "content": "We are hiring a Data Scientist in San Francisco, CA."}],
  tools=function_definition
)

print(response.choices[0].message.tool_calls[0].function.arguments)
```

**Output:**

```json
{"job": "Data Scientist", "location": "San Francisco, CA"}
```

üß† *Ph·ªèng v·∫•n:*

> ‚ÄúFunction calling d√πng ƒë·ªÉ l√†m g√¨?‚Äù
> ‚úÖ Tr·∫£ l·ªùi: ‚Äúƒê·ªÉ chuy·ªÉn ƒë·∫ßu ra ng√¥n ng·ªØ t·ª± nhi√™n th√†nh d·ªØ li·ªáu c√≥ c·∫•u tr√∫c, ho·∫∑c g·ªçi API ngo√†i.‚Äù

---

### üß© 2.4 G·ªçi nhi·ªÅu h√†m song song (Parallel Function Calling)

```python
function_definition.append({
  "type": "function",
  "function": {
    "name": "get_timezone",
    "description": "Return timezone for a location",
    "parameters": {"type": "object", "properties": {"timezone": {"type": "string"}}}
  }
})

response = client.chat.completions.create(
  model="gpt-4o-mini",
  messages=messages,
  tools=function_definition
)

print(response.choices[0].message.tool_calls[0].function.arguments)
print(response.choices[0].message.tool_calls[1].function.arguments)
```

üß† *K·ªπ nƒÉng ph·ªèng v·∫•n n√¢ng cao:*

> ‚ÄúL√†m sao ƒë·ªÉ √©p m√¥ h√¨nh ch·ªâ g·ªçi 1 h√†m c·ª• th·ªÉ?‚Äù
> ‚úÖ D√πng `tool_choice={"type": "function", "function": {"name": "extract_job_info"}}`

---

### üß© 2.5 G·ªçi API ngo√†i qua `requests`

```python
import requests

def get_artwork(keyword):
    url = "https://api.artic.edu/api/v1/artworks/search"
    params = {"q": keyword}
    return requests.get(url, params=params).text
```

Sau ƒë√≥ g·ªçi:

```python
if response.choices[0].finish_reason == "tool_calls":
    call = response.choices[0].message.tool_calls[0].function
    if call.name == "get_artwork":
        kw = json.loads(call.arguments)["artwork keyword"]
        print(get_artwork(kw))
```

üí° *·ª®ng d·ª•ng th·ª±c t·∫ø:*

* Chatbot truy v·∫•n c∆° s·ªü d·ªØ li·ªáu
* AI travel planner (g·ªçi API th·ªùi ti·∫øt, ƒë·ªãa ƒëi·ªÉm)
* AI h·ªó tr·ª£ HR (tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ JD)

---

## üß∞ PH·∫¶N 3: QU·∫¢N L√ù L·ªñI, RATE LIMITS & TOKEN

---

### ‚ö†Ô∏è 3.1 Error Handling

C√°c l·ªói ph·ªï bi·∫øn trong OpenAI API:

| Lo·∫°i l·ªói              | Nguy√™n nh√¢n           | C√°ch x·ª≠ l√Ω                      |
| --------------------- | --------------------- | ------------------------------- |
| `AuthenticationError` | Sai API key           | Ki·ªÉm tra key, load t·ª´ env       |
| `RateLimitError`      | G·ªçi qu√° nhi·ªÅu request | D√πng batching, retry            |
| `BadRequestError`     | Sai c·∫•u tr√∫c messages | Ki·ªÉm tra role h·ª£p l·ªá            |
| `APIConnectionError`  | M·∫•t k·∫øt n·ªëi           | Th·ª≠ l·∫°i ho·∫∑c b√°o l·ªói ng∆∞·ªùi d√πng |

---

### ‚öôÔ∏è 3.2 Retry t·ª± ƒë·ªông v·ªõi `tenacity`

```python
from tenacity import retry, stop_after_attempt, wait_random_exponential

@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))
def get_response(model, message):
    return client.chat.completions.create(
        model=model,
        messages=[message]
    )
```

üí° *Ph·ªèng v·∫•n:*

> ‚ÄúN·∫øu g·∫∑p l·ªói 429 Rate Limit, b·∫°n l√†m g√¨?‚Äù
> ‚úÖ ‚ÄúT√¥i d√πng retry c√≥ exponential backoff ho·∫∑c gom batch c√°c request.‚Äù

---

### üß© 3.3 Batching

```python
countries = ["USA", "Ireland", "India"]
messages = [{"role": "system", "content": "Return each country and its capital."}]
[ messages.append({"role": "user", "content": c}) for c in countries ]

response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=messages
)
```

---

### üî¢ 3.4 T√≠nh s·ªë tokens (gi·ªõi h·∫°n ƒë·ªô d√†i input)

```python
import tiktoken
encoding = tiktoken.encoding_for_model("gpt-4o-mini")
prompt = "Tokens can be words or subwords."
print(len(encoding.encode(prompt)))
```

üß† *Ph·ªèng v·∫•n:*

> ‚ÄúN·∫øu m√¥ h√¨nh tr·∫£ incomplete output, nguy√™n nh√¢n?‚Äù
> ‚úÖ ‚ÄúH·∫øt token output ho·∫∑c prompt qu√° d√†i.‚Äù

---

## üß± PH·∫¶N 4: MODERATION & SAFETY

---

### üîí 4.1 Moderation API

Ki·ªÉm tra input c√≥ vi ph·∫°m ch√≠nh s√°ch kh√¥ng (b·∫°o l·ª±c, th√π gh√©t, t√¨nh d·ª•c, v.v.)

```python
moderation_response = client.moderations.create(input="Someone explodes in the game.")
print(moderation_response.results[0].categories.violence)
```

‚û°Ô∏è Output: `True`

---

### üß± 4.2 Prompt Guardrails

Gi·ªõi h·∫°n ch·ªß ƒë·ªÅ ho·∫∑c ch·∫∑n ‚Äúprompt injection‚Äù.

```python
user_request = "Describe the Exploding Kittens card game."
messages = [
  {"role": "system", "content": "You can only talk about chess. If not, say 'not allowed'."},
  {"role": "user", "content": user_request}
]

response = client.chat.completions.create(model="gpt-4o-mini", messages=messages)
print(response.choices[0].message.content)
```

‚û°Ô∏è Output: ‚ÄúApologies, but the topic is not allowed.‚Äù

---

### üß† 4.3 Validation & Adversarial Testing

* Test model v·ªõi **prompt ƒë·ªôc h·∫°i ho·∫∑c m√¢u thu·∫´n** ƒë·ªÉ ph√°t hi·ªán l·ªói.
* Th·ª±c h√†nh ki·ªÉm th·ª≠ v·ªõi Hugging Face datasets (`openai/evals`).

```python
response = client.chat.completions.create(
  model="gpt-4o-mini",
  messages=[
    {"role": "system", "content": "You analyze movie reviews."},
    {"role": "user", "content": "This movie had great actors but bad story."}
])
print(response.choices[0].message.content)
```

‚û°Ô∏è Output: ‚ÄúThe sentiment is negative.‚Äù

---

### üîë 4.4 B·∫£o m·∫≠t API key

* L∆∞u trong bi·∫øn m√¥i tr∆∞·ªùng (`os.getenv("OPENAI_API_KEY")`)
* Kh√¥ng commit v√†o GitHub
* Xoay key ƒë·ªãnh k·ª≥

```bash
export OPENAI_API_KEY="your_key_here"
```

---

## üß© PH·∫¶N 5: BEST PRACTICES TRONG S·∫¢N XU·∫§T

| H·∫°ng m·ª•c              | Th·ª±c h√†nh t·ªët                        |
| --------------------- | ------------------------------------ |
| **Error Handling**    | Lu√¥n try-except chi ti·∫øt             |
| **Moderation**        | Ki·ªÉm tra input tr∆∞·ªõc khi g·ª≠i model   |
| **Rate Limit**        | Batch + retry c√≥ backoff             |
| **Prompt Control**    | R√µ vai tr√≤ system/user               |
| **Validation**        | Adversarial testing tr∆∞·ªõc production |
| **Key Management**    | L∆∞u qua KMS ho·∫∑c Vault               |
| **Human in the Loop** | C√≥ ng∆∞·ªùi ki·ªÉm ƒë·ªãnh v·ªõi case nh·∫°y c·∫£m |

---

## üéØ C√ÇU H·ªéI

| C√¢u h·ªèi                            | Tr·∫£ l·ªùi m·∫´u                                        |
| ---------------------------------- | -------------------------------------------------- |
| Function calling d√πng l√†m g√¨?      | T·∫°o d·ªØ li·ªáu c√≥ c·∫•u tr√∫c ho·∫∑c g·ªçi API ngo√†i.        |
| L√†m sao gi·∫£m l·ªói RateLimitError?   | Batch, retry exponential, gi·∫£m token.              |
| Moderation API c√≥ vai tr√≤ g√¨?      | Ph√°t hi·ªán n·ªôi dung vi ph·∫°m ch√≠nh s√°ch.             |
| L√†m sao ƒë·∫£m b·∫£o JSON h·ª£p l·ªá?       | D√πng `response_format="json_object"`.              |
| Kh√°c nhau gi·ªØa system & user role? | System ƒë·ªãnh h∆∞·ªõng, user cung c·∫•p input.            |
| Prompt injection l√† g√¨?            | Khi user c·ªë g·∫Øng thay ƒë·ªïi h√†nh vi model tr√°i ph√©p. |
| C√°ch b·∫£o m·∫≠t API key?              | L∆∞u trong bi·∫øn m√¥i tr∆∞·ªùng, kh√¥ng push l√™n repo.    |

---
