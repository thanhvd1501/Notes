# ü¶ô TO√ÄN T·∫¨P V·ªÄ LLAMA 3

### (C·∫•u tr√∫c, c√°ch ch·∫°y local, tham s·ªë, chat roles, structured output, multi-turn, prompt engineering, l·ªói th∆∞·ªùng g·∫∑p & Q&A ph·ªèng v·∫•n)

---

## üß© 1. Gi·ªõi thi·ªáu v·ªÅ LLaMA

### 1.1 Ngu·ªìn g·ªëc & m·ª•c ti√™u

**LLaMA (Large Language Model Meta AI)** l√† d√≤ng m√¥ h√¨nh m√£ ngu·ªìn m·ªü c·ªßa Meta, ƒë·ªëi tr·ªçng v·ªõi GPT.
Phi√™n b·∫£n m·ªõi nh·∫•t ‚Äî **LLaMA 3** ‚Äî c√≥ k√≠ch th∆∞·ªõc t·ª´ 8B ƒë·∫øn 70B tham s·ªë, h·ªó tr·ª£:

* Nhi·ªÅu ng√¥n ng·ªØ (ƒëa ng·ªØ).
* Chat format t∆∞∆°ng th√≠ch OpenAI API (`messages`, `roles`).
* Ch·∫°y local b·∫±ng `llama.cpp` (file `.gguf`).
* Xu·∫•t JSON & multi-turn conversation.

### 1.2 ∆Øu ƒëi·ªÉm n·ªïi b·∫≠t

| T√≠nh nƒÉng                | L·ª£i √≠ch                                      |
| ------------------------ | -------------------------------------------- |
| M√£ ngu·ªìn m·ªü              | T·ª± do t√πy bi·∫øn, fine-tune local              |
| Hi·ªáu su·∫•t cao            | H·ªó tr·ª£ quantization (Q4, Q5, Q8) ƒë·ªÉ ch·∫°y CPU |
| API t∆∞∆°ng t·ª± OpenAI      | D·ªÖ t√≠ch h·ª£p pipeline c≈©                      |
| Structured output (JSON) | ƒê·∫ßu ra chu·∫©n h√≥a, d·ªÖ d√πng cho backend        |
| Chat role system         | Gi·ªØ ng·ªØ c·∫£nh h·ªôi tho·∫°i t·ª± nhi√™n              |

---

## ‚öôÔ∏è 2. C√†i ƒë·∫∑t & ch·∫°y m√¥ h√¨nh LLaMA local

### 2.1 C√†i th∆∞ vi·ªán

```bash
pip install llama-cpp-python
```

### 2.2 T·∫£i m√¥ h√¨nh `.gguf`

T·∫£i t·ª´ Hugging Face ho·∫∑c Meta (t√πy license).
V√≠ d·ª•: `TheBloke/Llama-3-8B-Instruct-GGUF`.

---

### 2.3 Ch·∫°y inference ƒë·∫ßu ti√™n

```python
from llama_cpp import Llama

llm = Llama(model_path="llama-3-8b-instruct.Q4_K_M.gguf")

out = llm("Explain the concept of reinforcement learning in 3 bullet points.")
print(out["choices"][0]["text"])
```

üìò **Gi·∫£i th√≠ch:**

* `model_path` ‚Üí file `.gguf` ƒë√£ t·∫£i.
* Output l√† dict gi·ªëng OpenAI response.
* N·ªôi dung n·∫±m ·ªü `choices[0]['text']`.

üß† **H·ªèi ph·ªèng v·∫•n:**

> ‚ÄúLLaMA 3 c√≥ kh√°c g√¨ GPT kh√¥ng?‚Äù
> ‚úÖ ‚ÄúV·ªÅ ki·∫øn tr√∫c Transformer l√† t∆∞∆°ng t·ª±, nh∆∞ng LLaMA l√† open-source, c√≥ th·ªÉ ch·∫°y local v√† t√πy ch·ªânh, c√≤n GPT l√† closed-source, ch·ªâ ch·∫°y qua API.‚Äù

---

## üéõÔ∏è 3. C√°c tham s·ªë ƒëi·ªÅu khi·ªÉn ƒë·∫ßu ra

### 3.1 Tham s·ªë c∆° b·∫£n

| Tham s·ªë       | √ù nghƒ©a                              | ·∫¢nh h∆∞·ªüng                        |
| ------------- | ------------------------------------ | -------------------------------- |
| `temperature` | M·ª©c ƒë·ªô s√°ng t·∫°o (0‚Äì1.5)              | Th·∫•p = ch√≠nh x√°c, cao = s√°ng t·∫°o |
| `top_k`       | Gi·ªõi h·∫°n s·ªë token ƒë∆∞·ª£c ch·ªçn m·ªói b∆∞·ªõc | Gi·∫£m ng·∫´u nhi√™n khi nh·ªè          |
| `top_p`       | X√°c su·∫•t t√≠ch l≈©y c·∫Øt ng·∫´u nhi√™n     | 0.9 ‚Üí ph·ªï bi·∫øn                   |
| `max_tokens`  | Gi·ªõi h·∫°n ƒë·ªô d√†i output               | Tr√°nh output qu√° d√†i             |

---

### 3.2 Th·ª±c h√†nh

```python
brief = llm(
    "Describe an electric car.",
    temperature=0.2, top_k=1, top_p=0.5, max_tokens=20
)
creative = llm(
    "Describe an electric car.",
    temperature=0.9, top_k=50, top_p=0.95, max_tokens=80
)
print("Brief:", brief["choices"][0]["text"])
print("Creative:", creative["choices"][0]["text"])
```

üí° Kinh nghi·ªám:

* D√πng `temperature < 0.3` cho **task ch√≠nh x√°c (t√≥m t·∫Øt, tr√≠ch th√¥ng tin)**.
* D√πng `temperature ~ 0.8` cho **task s√°ng t·∫°o (vi·∫øt content, brainstorming)**.

üß† **H·ªèi ph·ªèng v·∫•n:**

> ‚ÄúKh√°c bi·ªát gi·ªØa top-k v√† top-p sampling?‚Äù
> ‚úÖ ‚ÄúTop-k ch·ªçn K token x√°c su·∫•t cao nh·∫•t, top-p ch·ªçn theo ng∆∞·ª°ng x√°c su·∫•t t√≠ch l≈©y (nhi·ªÅu ho·∫∑c √≠t token t√πy context).‚Äù

---

## üí¨ 4. Chat role system (System/User/Assistant)

### 4.1 C·∫•u tr√∫c chat

LLaMA 3 h·ªó tr·ª£ **chat completion API t∆∞∆°ng t·ª± OpenAI**, g·ªìm 3 vai tr√≤:

| Role        | Vai tr√≤                    |
| ----------- | -------------------------- |
| `system`    | ƒê·ªãnh h∆∞·ªõng h√†nh vi m√¥ h√¨nh |
| `user`      | C√¢u h·ªèi / ƒë·∫ßu v√†o          |
| `assistant` | C√¢u tr·∫£ l·ªùi c·ªßa model      |

---

### 4.2 V√≠ d·ª• th·ª±c t·∫ø

```python
messages = [
    {"role": "system", "content": "You are a helpful data science tutor."},
    {"role": "user", "content": "Explain PCA in simple terms."}
]
out = llm.create_chat_completion(messages=messages)
print(out["choices"][0]["message"]["content"])
```

üß† **Gi·∫£i th√≠ch:**

* L·ªánh `create_chat_completion` duy tr√¨ **ng·ªØ c·∫£nh h·ªôi tho·∫°i**.
* Role `system` n√™n ƒë∆∞·ª£c d√πng ƒë·∫ßu ti√™n ƒë·ªÉ ƒë·ªãnh h∆∞·ªõng ‚Äúnh√¢n c√°ch‚Äù model.

üìò *Ngu·ªìn:* `chapter1-llama.pdf` ‚Äì ph·∫ßn Chat Roles.

---

## üß± 5. Structured Output (JSON, Schema)

### 5.1 Xu·∫•t JSON th√¥

```python
resp = llm.create_chat_completion(
    messages=[
        {"role": "system", "content": "You are a weather API returning JSON only."},
        {"role": "user", "content": "Weather in Tokyo now?"}
    ],
    response_format="json_object"
)
print(resp["choices"][0]["message"]["content"])
```

üìò **Gi·∫£i th√≠ch:**

* `response_format="json_object"` √©p model tr·∫£ JSON h·ª£p l·ªá.
* D√πng ƒë·ªÉ t√≠ch h·ª£p v·ªõi app/backend d·ªÖ d√†ng.

---

### 5.2 ƒê·ªãnh schema JSON (c√≥ c·∫•u tr√∫c)

```python
schema = {
  "type": "object",
  "properties": {
    "temperature": {"type": "string"},
    "humidity": {"type": "string"},
    "condition": {"type": "string"}
  },
  "required": ["temperature", "condition"]
}

resp = llm.create_chat_completion(
    messages=[{"role": "user", "content": "Give Tokyo weather"}],
    response_format={"type": "json_schema", "json_schema": schema}
)
print(resp["choices"][0]["message"]["content"])
```

üí° **·ª®ng d·ª•ng:**

* Chatbot data ‚Üí API JSON tr·∫£ k·∫øt qu·∫£ c√≥ c·∫•u tr√∫c.
* G·∫Øn v·ªõi FastAPI ho·∫∑c Streamlit ƒë·ªÉ hi·ªÉn th·ªã b·∫£ng d·ªØ li·ªáu.

üß† **H·ªèi ph·ªèng v·∫•n:**

> ‚ÄúT·∫°i sao structured output quan tr·ªçng?‚Äù
> ‚úÖ ‚ÄúGi√∫p model t∆∞∆°ng t√°c tr·ª±c ti·∫øp v·ªõi h·ªá th·ªëng l·∫≠p tr√¨nh, tr√°nh parsing l·ªói, tƒÉng t√≠nh t·ª± ƒë·ªông h√≥a.‚Äù

---

## üîÅ 6. Multi-turn Conversation (h·ªôi tho·∫°i nhi·ªÅu l∆∞·ª£t)

### 6.1 V·∫•n ƒë·ªÅ

Model c·∫ßn ‚Äúnh·ªõ‚Äù ng·ªØ c·∫£nh tr∆∞·ªõc (history).
N·∫øu kh√¥ng, m·ªói c√¢u h·ªèi m·ªõi b·ªã coi nh∆∞ h·ªôi tho·∫°i m·ªõi.

---

### 6.2 C√°ch l√†m: l∆∞u `messages` l·ªãch s·ª≠

```python
class ChatSession:
    def __init__(self, llm):
        self.llm = llm
        self.history = [{"role": "system", "content": "You are an AI assistant."}]
    
    def ask(self, text):
        self.history.append({"role": "user", "content": text})
        out = self.llm.create_chat_completion(messages=self.history)
        msg = out["choices"][0]["message"]
        self.history.append(msg)
        return msg["content"]

session = ChatSession(llm)
print(session.ask("Who is Alan Turing?"))
print(session.ask("What was his main contribution?"))
```

üìò *Ngu·ªìn:* `llama.txt` & `chapter2-llama.pdf`.

üß† **L·ª£i √≠ch:**

* Duy tr√¨ ng·ªØ c·∫£nh.
* M√¥ ph·ªèng h·ªôi tho·∫°i t·ª± nhi√™n.
* D·ªÖ m·ªü r·ªông cho chatbot c√≥ b·ªô nh·ªõ ng·∫Øn h·∫°n.

---

## üß† 7. Prompt Engineering n√¢ng cao

### 7.1 Zero-shot Prompting

Ch·ªâ cung c·∫•p h∆∞·ªõng d·∫´n m√¥ t·∫£ nhi·ªám v·ª•.

```python
prompt = "Classify the following text as Positive, Negative, or Neutral:\n\n'The movie was boring.'"
print(llm(prompt))
```

üí° *M·∫πo:*
Th√™m ‚Äú**INSTRUCTION:**‚Äù ho·∫∑c ‚Äú**QUESTION:**‚Äù gi√∫p model ph√¢n t√°ch r√µ input vs y√™u c·∫ßu.

---

### 7.2 Few-shot Prompting

Cung c·∫•p **m·∫´u v√≠ d·ª•** ƒë·ªÉ model h·ªçc c√°ch ph·∫£n h·ªìi.

```python
prompt = """Translate English to French:

EN: Hello
FR: Bonjour
EN: Good morning
FR:"""
print(llm(prompt))
```

üß† *Ph·ªèng v·∫•n:*

> ‚ÄúFew-shot gi√∫p g√¨ so v·ªõi zero-shot?‚Äù
> ‚úÖ ‚ÄúN√≥ cho m√¥ h√¨nh hi·ªÉu format v√† ng·ªØ c·∫£nh mong mu·ªën.‚Äù

---

### 7.3 Stop Sequences

Gi√∫p **d·ª´ng output** t·∫°i chu·ªói c·ª• th·ªÉ (vd: `"Q:"`, `"User:"`).

```python
out = llm(
    "Q: What is 2+2?\nA:",
    stop=["Q:"]
)
print(out["choices"][0]["text"])
```

üí° *·ª®ng d·ª•ng:* tr√°nh ‚Äúl·∫°c ƒë·ªÅ‚Äù khi model t·∫°o th√™m c√¢u h·ªèi gi·∫£.

---

## üö´ 8. L·ªói th∆∞·ªùng g·∫∑p & c√°ch kh·∫Øc ph·ª•c

| L·ªói                        | Nguy√™n nh√¢n                               | C√°ch kh·∫Øc ph·ª•c                                         |
| -------------------------- | ----------------------------------------- | ------------------------------------------------------ |
| Output l·ªôn x·ªôn, kh√¥ng JSON | Kh√¥ng ƒë·∫∑t `response_format="json_object"` | Th√™m `response_format` ho·∫∑c prompt ‚ÄúReturn valid JSON‚Äù |
| Model qu√™n ng·ªØ c·∫£nh        | Kh√¥ng l∆∞u `messages`                      | L∆∞u `history` to√†n h·ªôi tho·∫°i                           |
| C√¢u tr·∫£ l·ªùi qu√° d√†i        | Kh√¥ng set `max_tokens` ho·∫∑c `stop`        | Gi·ªõi h·∫°n `max_tokens`                                  |
| Qu√° ch·∫≠m                   | File GGUF qu√° l·ªõn                         | D√πng quantization Q4_K_M                               |

---

## üíº 9. C√¢u h·ªèi th∆∞·ªùng g·∫∑p
| C√¢u h·ªèi                             | Tr·∫£ l·ªùi g·ª£i √Ω                                                                 |
| ----------------------------------- | ----------------------------------------------------------------------------- |
| LLaMA l√† g√¨?                        | L√† h·ªç m√¥ h√¨nh ng√¥n ng·ªØ m√£ ngu·ªìn m·ªü c·ªßa Meta, t∆∞∆°ng t·ª± GPT.                    |
| LLaMA 3 c√≥ g√¨ n·ªïi b·∫≠t?              | Hi·ªáu su·∫•t cao, open-source, t∆∞∆°ng th√≠ch OpenAI API, h·ªó tr·ª£ JSON & multi-turn. |
| temperature ·∫£nh h∆∞·ªüng th·∫ø n√†o?      | Quy·∫øt ƒë·ªãnh m·ª©c ng·∫´u nhi√™n ‚Äì th·∫•p ch√≠nh x√°c, cao s√°ng t·∫°o.                     |
| top-k vs top-p kh√°c nhau ra sao?    | top-k ch·ªçn K token x√°c su·∫•t cao, top-p ch·ªçn theo ng∆∞·ª°ng x√°c su·∫•t t√≠ch l≈©y.    |
| Chat roles l√† g√¨?                   | system ƒë·ªãnh h∆∞·ªõng h√†nh vi, user cung c·∫•p c√¢u h·ªèi, assistant tr·∫£ l·ªùi.          |
| Structured output quan tr·ªçng kh√¥ng? | R·∫•t ‚Äì gi√∫p ·ª©ng d·ª•ng backend ƒë·ªçc k·∫øt qu·∫£ ch√≠nh x√°c & t·ª± ƒë·ªông.                  |
| Stop sequences d√πng khi n√†o?        | Khi c·∫ßn d·ª´ng sinh vƒÉn b·∫£n ·ªü m·ªôt v·ªã tr√≠ c·ªë ƒë·ªãnh.                               |
| Multi-turn ho·∫°t ƒë·ªông ra sao?        | L∆∞u l·ªãch s·ª≠ `messages` v√† truy·ªÅn l·∫°i cho model ƒë·ªÉ duy tr√¨ ng·ªØ c·∫£nh.           |

---

