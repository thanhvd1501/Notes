# ğŸ§  TOÃ€N Táº¬P: KIáº¾N TRÃšC Há»† THá»NG AI & OPENAI API

---

## âš™ï¸ **CHÆ¯Æ NG 1 â€“ Ná»€N Táº¢NG Vá»€ Há»† THá»NG AI**

---

### 1.1. KhÃ¡i niá»‡m cÆ¡ báº£n

#### ğŸ¤– TrÃ­ tuá»‡ nhÃ¢n táº¡o (AI)

LÃ  **kháº£ nÄƒng cá»§a mÃ¡y tÃ­nh mÃ´ phá»ng hÃ nh vi thÃ´ng minh cá»§a con ngÆ°á»i**: hiá»ƒu, suy luáº­n, há»c há»i, vÃ  hÃ nh Ä‘á»™ng.

**PhÃ¢n loáº¡i chÃ­nh:**

| Loáº¡i AI      | Äáº·c Ä‘iá»ƒm                      | VÃ­ dá»¥           |
| ------------ | ----------------------------- | --------------- |
| *Narrow AI*  | Chá»‰ lÃ m 1 viá»‡c cá»¥ thá»ƒ         | ChatGPT, Siri   |
| *General AI* | CÃ³ tÆ° duy tá»•ng quÃ¡t nhÆ° ngÆ°á»i | (chÆ°a Ä‘áº¡t Ä‘Æ°á»£c) |
| *Super AI*   | VÆ°á»£t trÃ­ tuá»‡ con ngÆ°á»i        | (giáº£ thuyáº¿t)    |

---

### 1.2. CÃ¡c thÃ nh pháº§n chÃ­nh trong má»™t há»‡ thá»‘ng AI hiá»‡n Ä‘áº¡i

1. **Dá»¯ liá»‡u (Data Layer)**
   â†’ Thu tháº­p, lÃ m sáº¡ch, chuáº©n hÃ³a.
   â†’ ÄÃ³ng vai trÃ² â€œnhiÃªn liá»‡uâ€ cho má»i mÃ´ hÃ¬nh.

2. **MÃ´ hÃ¬nh (Model Layer)**
   â†’ NÆ¡i huáº¥n luyá»‡n, fine-tune, vÃ  inference.
   â†’ Dá»±a trÃªn kiáº¿n trÃºc Transformer, LLM, CNN,...

3. **Háº¡ táº§ng (Infrastructure)**
   â†’ GPU/TPU, Vector DB, API Gateway, Cache Layer.

4. **Lá»›p á»©ng dá»¥ng (Application Layer)**
   â†’ Gá»“m chatbot, recommender, document Q&A, automation...

---

### 1.3. Chu trÃ¬nh phÃ¡t triá»ƒn há»‡ thá»‘ng AI

```text
Data â†’ Preprocessing â†’ Model Training â†’ Evaluation â†’ Deployment â†’ Monitoring
```

**Chi tiáº¿t tá»«ng bÆ°á»›c:**

* **Preprocessing**: loáº¡i bá» nhiá»…u, tokenization, embedding.
* **Training**: tá»‘i Æ°u hÃ m máº¥t mÃ¡t (loss), Ä‘iá»u chá»‰nh hyperparameters.
* **Evaluation**: Ä‘o báº±ng Accuracy, F1, BLEU, ROUGE, nDCG...
* **Deployment**: Ä‘Ã³ng gÃ³i model â†’ API / container / service.
* **Monitoring**: theo dÃµi drift, log, chi phÃ­, latency.

---

### 1.4. Pipeline AI cÆ¡ báº£n

VÃ­ dá»¥ há»‡ thá»‘ng **AI Q&A ná»™i bá»™**:

```
User â†’ Query â†’ Embedding â†’ Vector Search â†’ Context Retrieval â†’ GPT Response
```

* **Embedding**: chuyá»ƒn text thÃ nh vector ngá»¯ nghÄ©a.
* **Vector DB**: lÆ°u cÃ¡c vector (Chroma, Pinecone,...).
* **LLM (GPT)**: sinh cÃ¢u tráº£ lá»i cÃ³ ngá»¯ cáº£nh.

---

### 1.5. CÃ¡c loáº¡i há»‡ thá»‘ng AI thÆ°á»ng gáº·p

| Há»‡ thá»‘ng           | Má»¥c tiÃªu                | CÃ´ng nghá»‡ chÃ­nh        |
| ------------------ | ----------------------- | ---------------------- |
| Chatbot thÃ´ng minh | TrÃ² chuyá»‡n tá»± nhiÃªn     | GPT, RAG               |
| Recommender System | Gá»£i Ã½ cÃ¡ nhÃ¢n hÃ³a       | Embeddings, Similarity |
| Document Assistant | Há»i Ä‘Ã¡p tá»« tÃ i liá»‡u     | Vector DB + LLM        |
| AI Agent           | Tá»± Ä‘á»™ng thá»±c thi tÃ¡c vá»¥ | Function Calling       |
| Speech-to-Text     | Nháº­n diá»‡n giá»ng nÃ³i     | Whisper, ASR models    |

---

### ğŸ§  CÃ¢u há»i phá»ng váº¥n:

* â€œPipeline AI tá»« input Ä‘áº¿n output hoáº¡t Ä‘á»™ng tháº¿ nÃ o?â€
* â€œKhÃ¡c biá»‡t giá»¯a model-based vÃ  retrieval-based system?â€
* â€œVÃ¬ sao cáº§n monitoring khi triá»ƒn khai model?â€

---

## ğŸ¤– **CHÆ¯Æ NG 2 â€“ OPENAI API & á»¨NG Dá»¤NG TRONG Há»† THá»NG AI**

---

### 2.1. Kiáº¿n trÃºc OpenAI API

Gá»“m 3 lá»›p:

1. **Chat Models** â€“ sinh ngÃ´n ngá»¯ tá»± nhiÃªn (GPT-4, GPT-4o-mini).
2. **Embedding Models** â€“ mÃ£ hÃ³a vector (text-embedding-3).
3. **Moderation Models** â€“ phÃ¡t hiá»‡n ná»™i dung nháº¡y cáº£m.

Má»—i láº§n gá»i API lÃ  má»™t **â€œCompletion Requestâ€**.

---

### 2.2. Chat Completion API

```python
from openai import OpenAI
client = OpenAI()

response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "You are a Python tutor."},
        {"role": "user", "content": "Explain the difference between list and tuple."}
    ]
)
print(response.choices[0].message.content)
```

ğŸ§© **Cáº¥u trÃºc há»™i thoáº¡i:**

* `system` â†’ Ä‘á»‹nh hÆ°á»›ng hÃ nh vi.
* `user` â†’ cÃ¢u há»i.
* `assistant` â†’ pháº£n há»“i cá»§a mÃ´ hÃ¬nh.

---

### 2.3. Response Format â€“ JSON cÃ³ cáº¥u trÃºc

GiÃºp tÃ­ch há»£p trá»±c tiáº¿p vá»›i backend.

```python
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": "Return a JSON of 3 colors with RGB."}],
    response_format={"type": "json_object"}
)
```

Output:

```json
{
  "colors": [
    {"name": "red", "rgb": [255, 0, 0]},
    {"name": "green", "rgb": [0, 255, 0]},
    {"name": "blue", "rgb": [0, 0, 255]}
  ]
}
```

---

### 2.4. Function Calling â€“ cho phÃ©p GPT gá»i API tháº­t

**Má»¥c tiÃªu:** GPT khÃ´ng chá»‰ â€œnÃ³iâ€ mÃ  cÃ²n â€œhÃ nh Ä‘á»™ngâ€.

```python
tools = [{
  "type": "function",
  "function": {
    "name": "get_weather",
    "description": "Return weather info for a city",
    "parameters": {"type": "object", "properties": {"city": {"type": "string"}}}
  }
}]

response = client.chat.completions.create(
  model="gpt-4o-mini",
  messages=[{"role": "user", "content": "What's the weather in Tokyo?"}],
  tools=tools
)
print(response.choices[0].message.tool_calls)
```

Khi model gá»i `get_weather`, backend cÃ³ thá»ƒ thá»±c thi API tháº­t.

---

### 2.5. Temperature, Top_p, Max_tokens

| Tham sá»‘         | áº¢nh hÆ°á»Ÿng                              | DÃ¹ng khi               |
| --------------- | -------------------------------------- | ---------------------- |
| **temperature** | Äá»™ sÃ¡ng táº¡o (0 = chÃ­nh xÃ¡c, 1 = tá»± do) | Viáº¿t content           |
| **top_p**       | XÃ¡c suáº¥t chá»n token (nucleus sampling) | Giá»¯ Ä‘a dáº¡ng ngÃ´n ngá»¯   |
| **max_tokens**  | Giá»›i háº¡n Ä‘á»™ dÃ i output                 | NgÄƒn model nÃ³i quÃ¡ dÃ i |

---

### 2.6. Moderation â€“ kiá»ƒm duyá»‡t an toÃ n

```python
mod = client.moderations.create(input="I want to build a bomb.")
print(mod.results[0].categories)
```

Náº¿u káº¿t quáº£ `violence=True` â†’ cháº·n yÃªu cáº§u.

---

### 2.7. Cost & Token Tracking

```python
import tiktoken
enc = tiktoken.encoding_for_model("gpt-4o-mini")
tokens = len(enc.encode("Hello world"))
print(tokens)
```

â†’ Má»—i model cÃ³ giÃ¡/token khÃ¡c nhau.
VÃ­ dá»¥ `gpt-4o-mini`:

* Input: $0.15 / 1M tokens
* Output: $0.6 / 1M tokens

---

### ğŸ§  CÃ¢u há»i phá»ng váº¥n:

* â€œTemperature = 0.8 nghÄ©a lÃ  gÃ¬?â€
* â€œFunction calling hoáº¡t Ä‘á»™ng tháº¿ nÃ o?â€
* â€œModeration cÃ³ báº¯t buá»™c khÃ´ng?â€
* â€œToken lÃ  gÃ¬ vÃ  vÃ¬ sao pháº£i quáº£n lÃ½ chi phÃ­?â€

---

## ğŸ§± **CHÆ¯Æ NG 3 â€“ XÃ‚Y Dá»°NG Há»† THá»NG AI HOÃ€N CHá»ˆNH**

---

### 3.1. MÃ´ hÃ¬nh kiáº¿n trÃºc tá»•ng thá»ƒ

```
User â†’ API Gateway â†’ LLM Layer â†’ Vector Database â†’ External Tools â†’ Response
```

CÃ¡c lá»›p chÃ­nh:

1. **Frontend / Input Layer** â€“ ngÆ°á»i dÃ¹ng hoáº·c API nháº­n input.
2. **LLM Layer (OpenAI)** â€“ xá»­ lÃ½ logic, gá»i function.
3. **Vector Layer (Chroma / Pinecone)** â€“ tÃ¬m ngá»¯ cáº£nh.
4. **External Tools** â€“ API, DB, search engine.
5. **Monitoring Layer** â€“ log, token, lá»—i, cache.

---

### 3.2. XÃ¢y dá»±ng Document Q&A System (RAG pipeline)

```python
from openai import OpenAI
import chromadb
client = OpenAI()

# 1ï¸âƒ£ Táº¡o ChromaDB
chroma_client = chromadb.PersistentClient(path="./knowledge")
collection = chroma_client.create_collection(name="docs")

# 2ï¸âƒ£ ThÃªm tÃ i liá»‡u
collection.add(ids=["1"], documents=["AI is transforming the world of automation."])

# 3ï¸âƒ£ Embed cÃ¢u há»i
query = "What is the impact of AI on automation?"
query_emb = client.embeddings.create(model="text-embedding-3-small", input=query).data[0].embedding

# 4ï¸âƒ£ TÃ¬m kiáº¿m vector gáº§n nháº¥t
results = collection.query(query_embeddings=[query_emb], n_results=1)
context = results["documents"][0][0]

# 5ï¸âƒ£ Gá»­i cÃ¢u há»i kÃ¨m ngá»¯ cáº£nh cho GPT
prompt = f"Context: {context}\nQuestion: {query}"
answer = client.chat.completions.create(model="gpt-4o-mini", messages=[{"role": "user", "content": prompt}])
print(answer.choices[0].message.content)
```

ğŸ§  ÄÃ¢y lÃ  **RAG (Retrieval-Augmented Generation)** â€” kiáº¿n trÃºc phá»• biáº¿n nháº¥t trong phá»ng váº¥n ká»¹ sÆ° LLM.

---

### 3.3. Logging, Retry & Error Handling

```python
from tenacity import retry, stop_after_attempt, wait_random_exponential

@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(5))
def get_answer(prompt):
    return client.chat.completions.create(model="gpt-4o-mini", messages=[{"role": "user", "content": prompt}])
```

â†’ DÃ¹ng **exponential backoff** Ä‘á»ƒ trÃ¡nh rate-limit.

---

### 3.4. Triá»ƒn khai Production

**CÃ¡c thÃ nh pháº§n thá»±c táº¿:**

* FastAPI / Flask â†’ REST API service.
* Redis / PostgreSQL â†’ cache vÃ  logs.
* Supervisor / Docker â†’ cháº¡y bá»n vá»¯ng.
* Prometheus / Grafana â†’ theo dÃµi latency & usage.

---

### 3.5. Checklist phá»ng váº¥n vá» há»‡ thá»‘ng AI

| Chá»§ Ä‘á»           | CÃ¢u há»i phá»ng váº¥n Ä‘iá»ƒn hÃ¬nh                       |
| ---------------- | ------------------------------------------------- |
| API              | â€œHÃ£y mÃ´ táº£ flow cá»§a OpenAI Chat Completion.â€      |
| Embedding        | â€œEmbedding dÃ¹ng trong semantic search tháº¿ nÃ o?â€   |
| RAG              | â€œRAG khÃ¡c gÃ¬ fine-tune?â€                          |
| Function calling | â€œCÃ¡ch dÃ¹ng function calling Ä‘á»ƒ truy cáº­p DB?â€      |
| Monitoring       | â€œTheo dÃµi drift & chi phÃ­ model ra sao?â€          |
| Prompting        | â€œKhÃ¡c biá»‡t giá»¯a zero-shot vÃ  few-shot prompting?â€ |

---

## ğŸ¯ Tá»”NG Káº¾T CHO PHá»NG Váº¤N

1. **Biáº¿t pipeline tá»•ng thá»ƒ:**
   `Input â†’ Embedding â†’ Vector Search â†’ Context â†’ GPT Answer`.

2. **Hiá»ƒu rÃµ tá»«ng thÃ nh pháº§n:**
   Chat Completion / Embedding / Moderation / Function Calling.

3. **Náº¯m best practices:**
   Guardrails, Retry, Token limits, Cost control.

4. **Thá»±c hÃ nh thá»±c táº¿:**
   Viáº¿t Ä‘Æ°á»£c app mini dÃ¹ng OpenAI API + Vector DB.

---

## ğŸ’¼ Mini Project báº¡n nÃªn lÃ m Ä‘á»ƒ chuáº©n bá»‹ phá»ng váº¥n

âœ… **AI Resume Reviewer:**

* Input: file CV â†’ GPT phÃ¢n tÃ­ch Ä‘iá»ƒm máº¡nh, yáº¿u, khuyáº¿n nghá»‹ cáº£i thiá»‡n.
* Output: JSON structured + lá»i khuyÃªn.
* Sá»­ dá»¥ng: `chat.completions`, `response_format`, `temperature=0.2`.

âœ… **RAG Chatbot ná»™i bá»™:**

* Ingest PDF â†’ Embed â†’ Vector DB â†’ GPT.
* Gáº¯n thÃªm logging & retry.

---
